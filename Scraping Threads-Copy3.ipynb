{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib2 import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from bson.objectid import ObjectId\n",
    "%matplotlib inline\n",
    "\n",
    "db_client = MongoClient()\n",
    "data = db_client['shopify']['forum']\n",
    "data2 = db_client['shopify_backup']\n",
    "users = db_client['shopify']['users']\n",
    "post_db = db_client['shopify']['posts']\n",
    "shopify_post_db = db_client['shopify']['shopify_posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'https://ecommerce.shopify.com/'\n",
    "forums_url = 'forums'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;padding:10px;\"><h1>Step 3: Scrape User and Topic Information</h1></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> CATEGORY: category-general-discussion\n",
      "SUBCATEGORY: category-off-topic\n",
      "PROCESSED 5/160 posts\n",
      "PROCESSED 10/160 posts\n",
      "PROCESSED 15/160 posts\n",
      "PROCESSED 20/160 posts\n",
      "PROCESSED 25/160 posts\n",
      "PROCESSED 30/160 posts\n",
      "PROCESSED 35/160 posts\n",
      "PROCESSED 40/160 posts\n",
      "PROCESSED 45/160 posts\n",
      "PROCESSED 50/160 posts\n",
      "PROCESSED 55/160 posts\n",
      "PROCESSED 60/160 posts\n",
      "PROCESSED 65/160 posts\n",
      "PROCESSED 70/160 posts\n",
      "PROCESSED 75/160 posts\n",
      "PROCESSED 80/160 posts\n",
      "PROCESSED 85/160 posts\n",
      "PROCESSED 90/160 posts\n",
      "PROCESSED 95/160 posts\n",
      "PROCESSED 100/160 posts\n",
      "PROCESSED 105/160 posts\n",
      "PROCESSED 110/160 posts\n",
      "PROCESSED 115/160 posts\n",
      "PROCESSED 120/160 posts\n",
      "PROCESSED 125/160 posts\n",
      "PROCESSED 130/160 posts\n",
      "PROCESSED 135/160 posts\n",
      "PROCESSED 140/160 posts\n",
      "PROCESSED 145/160 posts\n",
      "PROCESSED 150/160 posts\n",
      "PROCESSED 155/160 posts\n",
      "PROCESSED 160/160 posts\n",
      "SUBCATEGORY: category-entrepreneurship\n",
      "PROCESSED 5/100 posts\n",
      "PROCESSED 10/100 posts\n",
      "PROCESSED 15/100 posts\n",
      "PROCESSED 20/100 posts\n",
      "PROCESSED 25/100 posts\n",
      "PROCESSED 30/100 posts\n",
      "PROCESSED 35/100 posts\n",
      "PROCESSED 40/100 posts\n",
      "PROCESSED 45/100 posts\n",
      "PROCESSED 50/100 posts\n",
      "PROCESSED 55/100 posts\n",
      "PROCESSED 60/100 posts\n",
      "PROCESSED 65/100 posts\n",
      "PROCESSED 70/100 posts\n",
      "PROCESSED 75/100 posts\n",
      "PROCESSED 80/100 posts\n",
      "PROCESSED 85/100 posts\n",
      "PROCESSED 90/100 posts\n",
      "PROCESSED 95/100 posts\n",
      "PROCESSED 100/100 posts\n"
     ]
    }
   ],
   "source": [
    "for category in [data.find({'category':'category-general-discussion'})[0]]:\n",
    "    \n",
    "    print '-----> CATEGORY:', category['category']\n",
    "    for sub_cat_key in category[\"sub_cats\"]:\n",
    "        \n",
    "\n",
    "        print 'SUBCATEGORY: {sub_cat}'.format(sub_cat=sub_cat_key)\n",
    "\n",
    "\n",
    "        sub_cat = category['sub_cats'][sub_cat_key]\n",
    "        posts = []\n",
    "\n",
    "\n",
    "        # Run through each thread\n",
    "        for idx, url in enumerate(sub_cat['topic_urls']):\n",
    "\n",
    "            try:\n",
    "                topic_page = BeautifulSoup(urlopen(url))\n",
    "                thread = []\n",
    "\n",
    "                # Process original post\n",
    "                user_id, text, date = process_post(topic_page.find('div',{'class':'original-post'}))\n",
    "                shopify_post_db.insert_one({'user_id':user_id, 'date':date, 'text':text})\n",
    "\n",
    "                # Process each reply\n",
    "                for reply in topic_page.find_all('div',{'itemtype':'http://schema.org/UserComments'}):\n",
    "                    user_id, text, date = process_post(reply)\n",
    "                    shopify_post_db.insert_one({'user_id':user_id, 'date':date, 'text':text})\n",
    "\n",
    "\n",
    "                # Status Update\n",
    "                if (idx+1) % 5 == 0:\n",
    "                    print 'PROCESSED {idx}/{total} posts'.format(idx=(idx+1),total=len(sub_cat['topic_urls']))\n",
    "\n",
    "            except Exception as e:\n",
    "                print 'ERROR IN SUBCATEGORY: ', str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_post(post):\n",
    "    \n",
    "    user = post.find('div',{'class':'author'})\n",
    "    user_id = int(user.find('a',{'class':'username'}).get('href').split('/')[-1])\n",
    "    \n",
    "    # Add user to db if does not exist \n",
    "    if users.find({'id': user_id}).count() < 1:\n",
    "        name = user.find('a',{'class':'username'}).text.strip()\n",
    "        title = user.find_all('em')[0].text.strip().lower()\n",
    "        site = user.find_all('em')[-1].text.strip().lower()\n",
    "        posts = int(user.find('div',{'class':'stats'}).find('a').text.strip().lower())\n",
    "        users.insert_one({'id':user_id,'name':name,'title':title,'site':site, 'posts':posts })\n",
    "        \n",
    "    # Extract date\n",
    "    date = get_date(post)\n",
    "    \n",
    "    # Extract text\n",
    "    text = ' '.join([txt.text.lower() for txt in post.find('div',{'itemprop':'description'}).find_all('p')])\n",
    "    \n",
    "    return user_id, text, date\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime as dt\n",
    "months = ['january','february','march','april','may','june','july','august','september','october','november','december']\n",
    "\n",
    "def get_date(post):\n",
    "    \n",
    "    regexes = ['(\\d+) day','(\\d+) month', '(\\w+) (\\d+), (20\\d+)']\n",
    "    raw_date = post.find('div',{'class':'date'}).text.strip()\n",
    "    date = None\n",
    "    \n",
    "    for idx, reg in enumerate(regexes):\n",
    "        matches = re.search(reg, raw_date)\n",
    "        if matches:\n",
    "            if idx == 0:\n",
    "                date = dt.datetime.now() - dt.timedelta(days=int(matches.group(1)))\n",
    "            elif idx == 1:\n",
    "                date = dt.datetime.now() - dt.timedelta(days=int(matches.group(1))*30)\n",
    "            else:\n",
    "                date = dt.datetime(int(matches.group(3)), int(months.index(matches.group(1).lower())) + 1, int(matches.group(2)))\n",
    "\n",
    "    return date.strftime('%Y-%m-%d') if date else 'WHY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
